{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Usage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "This notebook will go over how to install this repo on an external server to run the training and inference.\n",
    "To begin, we'll first need to clone the repo"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!git clone https://github.com/ksanjeevan/crnn-audio-classification.git"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'crnn-audio-classification'...\n",
      "remote: Enumerating objects: 167, done.\u001b[K\n",
      "remote: Counting objects: 100% (26/26), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
      "remote: Total 167 (delta 10), reused 12 (delta 6), pack-reused 141\u001b[K\n",
      "Receiving objects: 100% (167/167), 3.57 MiB | 1.77 MiB/s, done.\n",
      "Resolving deltas: 100% (82/82), done.\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "e_cuSIyezXEp",
    "outputId": "b694fb03-5c0b-4951-fe8f-13cf2a0f4c25"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will also need to install the [torchaudio-contrib package](https://github.com/keunwoochoi/torchaudio-contrib). This is simple as cloneing the repo and using `pip` to install it "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!git clone https://github.com/keunwoochoi/torchaudio-contrib\n",
    "!pip install -e torchaudio-contrib"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'torchaudio-contrib'...\n",
      "remote: Enumerating objects: 308, done.\u001b[K\n",
      "remote: Total 308 (delta 0), reused 0 (delta 0), pack-reused 308\u001b[K\n",
      "Receiving objects: 100% (308/308), 1.93 MiB | 5.08 MiB/s, done.\n",
      "Resolving deltas: 100% (156/156), done.\n",
      "Obtaining file:///home/abs/abs/crnn-audio-classification/torchaudio-contrib\n",
      "Requirement already satisfied: torch in /home/abs/.local/lib/python3.8/site-packages (from torchaudio-contrib==0.1) (1.7.1+cu110)\n",
      "Requirement already satisfied: typing-extensions in /home/abs/.local/lib/python3.8/site-packages (from torch->torchaudio-contrib==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: numpy in /home/abs/.local/lib/python3.8/site-packages (from torch->torchaudio-contrib==0.1) (1.19.5)\n",
      "Installing collected packages: torchaudio-contrib\n",
      "  Running setup.py develop for torchaudio-contrib\n",
      "Successfully installed torchaudio-contrib\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "utIhHHd83zGS",
    "outputId": "ad1d5444-3d27-4c45-8780-ab69c9f384cf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll do some cleanup and move the repo into the root folder, which is optional"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!cp -r crnn-audio-classification/* ."
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3IoVML3kzYmV"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll install the other required packages. Note tensorboardX is optional. If you want to install tensorboardX, you'll also need to install Tensorflow as well"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "!pip install SoundFile\n",
    "!pip install git+https://github.com/ksanjeevan/torchparse.git"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting SoundFile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/abs/.local/lib/python3.8/site-packages (from SoundFile) (1.14.4)\n",
      "Requirement already satisfied: pycparser in /home/abs/.local/lib/python3.8/site-packages (from cffi>=1.0->SoundFile) (2.20)\n",
      "Installing collected packages: SoundFile\n",
      "Successfully installed SoundFile-0.10.3.post1\n",
      "Collecting git+https://github.com/ksanjeevan/torchparse.git\n",
      "  Cloning https://github.com/ksanjeevan/torchparse.git to /tmp/pip-req-build-q24clo1o\n",
      "  Running command git clone -q https://github.com/ksanjeevan/torchparse.git /tmp/pip-req-build-q24clo1o\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/abs/.local/lib/python3.8/site-packages (from torchparse==0.1) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.0 in /home/abs/.local/lib/python3.8/site-packages (from torchparse==0.1) (1.7.1+cu110)\n",
      "Requirement already satisfied: typing-extensions in /home/abs/.local/lib/python3.8/site-packages (from torch>=1.0->torchparse==0.1) (3.7.4.3)\n",
      "Building wheels for collected packages: torchparse\n",
      "  Building wheel for torchparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchparse: filename=torchparse-0.1-py3-none-any.whl size=7977 sha256=7589fb4ce010afe4871bc34ee65372bbfd5e8990ed1799908926185b4c9924e7\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-36hhb5fr/wheels/14/99/39/34754e0ce89e0a21e18986098cbc8346e7346b3cb7ce839129\n",
      "Successfully built torchparse\n",
      "Installing collected packages: torchparse\n",
      "Successfully installed torchparse-0.1\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "colab_type": "code",
    "id": "fVx3QyvN2b4s",
    "outputId": "f2b3e674-d72f-474f-9f0f-41047c57a68e"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#optional\n",
    "!pip install tensorboardX\n",
    "!pip install tensorboard\n",
    "!pip install tensorflow"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.4-py2.py3-none-any.whl (124 kB)\n",
      "\u001b[K     |████████████████████████████████| 124 kB 3.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/abs/.local/lib/python3.8/site-packages (from tensorboardX) (1.19.5)\n",
      "Collecting protobuf>=3.8.0\n",
      "  Downloading protobuf-3.17.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 5.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.9 in /usr/lib/python3/dist-packages (from protobuf>=3.8.0->tensorboardX) (1.14.0)\n",
      "Installing collected packages: protobuf, tensorboardX\n",
      "Successfully installed protobuf-3.17.3 tensorboardX-2.4\n",
      "Requirement already satisfied: tensorboard in /home/abs/.local/lib/python3.8/site-packages (2.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (0.13.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (0.4.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard) (2.22.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (1.19.5)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (1.35.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (2.0.1)\n",
      "Requirement already satisfied: wheel>=0.26 in /usr/lib/python3/dist-packages (from tensorboard) (0.34.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard) (45.2.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (1.39.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (3.17.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard) (3.1.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from absl-py>=0.4->tensorboard) (1.14.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/abs/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/abs/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.0-cp38-cp38-manylinux2010_x86_64.whl (458.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 458.4 MB 74 kB/s \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (2.6.0)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 100.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.37.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (0.13.0)\n",
      "Collecting wheel~=0.35\n",
      "  Downloading wheel-0.37.0-py2.py3-none-any.whl (35 kB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 202 kB/s \n",
      "\u001b[?25hCollecting keras~=2.6\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 2.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (3.17.3)\n",
      "Collecting tensorflow-estimator~=2.6\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 1.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy~=1.19.2 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.3 MB/s \n",
      "\u001b[?25hCollecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /home/abs/.local/lib/python3.8/site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 515 kB/s \n",
      "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.5)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard~=2.6->tensorflow) (2.22.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/abs/.local/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/abs/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/abs/.local/lib/python3.8/site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/abs/.local/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Building wheels for collected packages: termcolor, clang\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=afa705fd9fc2d740eb815fec0e1025ffbf646889d0ece0c3731fff604783363a\n",
      "  Stored in directory: /home/abs/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=ede0eb1020126a72af9c14bd1232bc749709620db0dc38ab9e3aa82973b39390\n",
      "  Stored in directory: /home/abs/.cache/pip/wheels/f1/60/77/22b9b5887bd47801796a856f47650d9789c74dc3161a26d608\n",
      "Successfully built termcolor clang\n",
      "\u001b[31mERROR: launchpadlib 1.10.13 requires testresources, which is not installed.\u001b[0m\n",
      "Installing collected packages: termcolor, h5py, wheel, six, keras-preprocessing, keras, tensorflow-estimator, gast, google-pasta, astunparse, clang, opt-einsum, flatbuffers, tensorflow\n",
      "Successfully installed astunparse-1.6.3 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-pasta-0.2.0 h5py-3.1.0 keras-2.6.0 keras-preprocessing-1.1.2 opt-einsum-3.3.0 six-1.15.0 tensorflow-2.6.0 tensorflow-estimator-2.6.0 termcolor-1.1.0 wheel-0.37.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Downloading the UrbanSound8k dataset\n",
    "To download the dataset, navigation to the [UrbanSoundDataSet webpage](https://urbansounddataset.weebly.com/urbansound8k.html) and navigate to the bottom of the page. \n",
    "There will be a simple [form](https://urbansounddataset.weebly.com/download-urbansound8k.html) that you will need to fill out before getting access to the dataset.\n",
    "\n",
    "Once its filled out, you will receive a url to download the dataset. Copy that link, and paste into the `{urbansound8k link}`. using `wget`, we'll download the url to the notebook"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "!wget {urbansound8k link}"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "--2021-08-18 20:17:49--  http://%7Burbansound8k/\n",
      "Resolving {urbansound8k ({urbansound8k)... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘{urbansound8k’\n",
      "--2021-08-18 20:17:49--  http://link%7D/\n",
      "Resolving link} (link})... failed: Name or service not known.\n",
      "wget: unable to resolve host address ‘link}’\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Once its downloaded, we will then need to untar the file. Just replace `{urbansound8k_downloaded_file}` with the name of the file. \n",
    "Optionally, we can removed the downloaded file here as well"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!tar -zxvf /home/abs/abs/crnn-audio-classification/crnn-audio-classification/UrbanSound8K.tar.gz\n",
    "\n",
    "# !rm -f {urbansound8k_downloaded_file}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "mDILa9uqDOrV",
    "outputId": "b5961199-dead-4e2f-f1c5-b91acb914015"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing the config file\n",
    "\n",
    "The config file is used to build out the training model. The only thing you will *need* to change is the path to the dataset.\n",
    "which is located in `data[\"path\"]`.\n",
    "You may also want to change the number of epochs(`data[\"train\"][\"epochs\"]`), when testing. Running the training with 10 epochs took about 10 minutes on a GPU. (You are running this on a GPU right :))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "json_config = {\n",
    "    \"name\"          :   \"Urban Testing\",\n",
    "    \"data\"          :   {\n",
    "                            \"type\"      :   \"CSVDataManager\",\n",
    "                            \"path\"      :   \"UrbanSound8K\",\n",
    "                            \"format\"    :   \"audio\",\n",
    "                            \"loader\"    :   {\n",
    "                                                \"shuffle\"       : True,\n",
    "                                                \"batch_size\"    : 24,\n",
    "                                                \"num_workers\"   : 4,\n",
    "                                                \"drop_last\"     : True\n",
    "                                            },\n",
    "                            \"splits\"    :   {\n",
    "                                                \"train\" : [1,2,3,4,5,6,7,8,9], \n",
    "                                                \"val\"   : [10]                                            \n",
    "                                            }\n",
    "                        },\n",
    "    \"transforms\"    :   {\n",
    "                            \"type\"      :   \"AudioTransforms\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"channels\"       : \"avg\",\n",
    "                                                \"noise\"    : [0.3, 0.001],\n",
    "                                                \"crop\"     : [0.4, 0.25]\n",
    "                                            }\n",
    "                        },\n",
    "    \"optimizer\"     :   {\n",
    "                            \"type\"      :   \"Adam\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"lr\"            : 0.002,\n",
    "                                                \"weight_decay\"  : 0.01,\n",
    "                                                \"amsgrad\"       : True\n",
    "                                            }\n",
    "                        },\n",
    "    \"lr_scheduler\"   :   {\n",
    "                            \"type\"      :   \"StepLR\",\n",
    "                            \"args\"      :   {\n",
    "                                                \"step_size\" : 10,\n",
    "                                                \"gamma\"     : 0.5\n",
    "                                            }\n",
    "                        },\n",
    "    \"model\"         :   {\n",
    "                            \"type\"      :   \"AudioCRNN\"\n",
    "                        },\n",
    "    \"train\"         :   {\n",
    "                            \"loss\"      :   \"nll_loss\",\n",
    "                            \"epochs\"    :   100,\n",
    "                            \"save_dir\"  :   \"saved_cv/\",\n",
    "                            \"save_p\"    :   1,\n",
    "                            \"verbosity\" :   2,\n",
    "                            \n",
    "                            \"monitor\"   :   \"min val_loss\",\n",
    "                            \"early_stop\":   8,\n",
    "                            \"tbX\"       :   True\n",
    "                        },\n",
    "    \"metrics\"       :   \"classification_metrics\"\n",
    "\n",
    "}"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7rJflAUKC4kU"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, we'll write this json out, in order for the model to read in this updated json file"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import json\n",
    "with open('my-config.json', 'w') as json_file:  \n",
    "  json.dump(json_config, json_file)"
   ],
   "outputs": [],
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9Y43AjFuF9Yf"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training\n",
    "Finally, we can start training the model. We'll be passing 3 parameters, with the first parameter being the action we want to take, which is `train`. You can use `train` to train the model, or `eval`, to perform evalation on the model. The `-c` parameter is the config file, which we just created, and `--cfg`, which is the layer configuration of the model."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "!python3 run.py train -c my-config.json --cfg crnn.cfg"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Compose(\n",
      "    ProcessChannels(mode=avg)\n",
      "    AdditiveNoise(prob=0.3, sig=0.001, dist_type=normal)\n",
      "    RandomCropLength(prob=0.4, sig=0.25, dist_type=half)\n",
      "    ToTensorAudio()\n",
      ")\n",
      "AudioCRNN(\n",
      "  (spec): MelspectrogramStretch(num_bands=128, fft_len=2048, norm=spec_whiten, stretch_param=[0.4, 0.4])\n",
      "  (net): ModuleDict(\n",
      "    (convs): Sequential(\n",
      "      (conv2d_0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0])\n",
      "      (batchnorm2d_0): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (elu_0): ELU(alpha=1.0)\n",
      "      (maxpool2d_0): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout_0): Dropout(p=0.1)\n",
      "      (conv2d_1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0])\n",
      "      (batchnorm2d_1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (elu_1): ELU(alpha=1.0)\n",
      "      (maxpool2d_1): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout_1): Dropout(p=0.1)\n",
      "      (conv2d_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=[0, 0])\n",
      "      (batchnorm2d_2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (elu_2): ELU(alpha=1.0)\n",
      "      (maxpool2d_2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
      "      (dropout_2): Dropout(p=0.1)\n",
      "    )\n",
      "    (recur): LSTM(128, 64, num_layers=2, bidirectional=True)\n",
      "    (dense): Sequential(\n",
      "      (dropout_3): Dropout(p=0.3)\n",
      "      (batchnorm1d_0): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (linear_0): Linear(in_features=128, out_features=10, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Trainable parameters: 256266\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"run.py\", line 179, in <module>\n",
      "    train_main(config, args.resume)\n",
      "  File \"run.py\", line 117, in train_main\n",
      "    train_logger=train_logger)\n",
      "  File \"/home/jupyter/crnn-audio-classification - UrbanSound8k/train/trainer.py\", line 19, in __init__\n",
      "    super(Trainer, self).__init__(model, loss, metrics, optimizer, resume, config, train_logger)\n",
      "  File \"/home/jupyter/crnn-audio-classification - UrbanSound8k/train/base_trainer.py\", line 21, in __init__\n",
      "    self.model = model.to(self.device)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 381, in to\n",
      "    return self._apply(convert)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 187, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\", line 187, in _apply\n",
      "    module._apply(fn)\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 117, in _apply\n",
      "    self.flatten_parameters()\n",
      "  File \"/opt/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\", line 113, in flatten_parameters\n",
      "    self.batch_first, bool(self.bidirectional))\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "GZ5AVLf5zjv6",
    "outputId": "8605180e-767a-4323-8b1d-49c771e946ca"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "After we have trainined the model, we can run inference on it.\n",
    "Call the `run.py` with 2 parameters. The first is a path to a sample audio audio file. For this example, we'll use a random audio sample from the UrbanSound8K dataset. The second parameter will be the path to the model checkpoint. It will look something like this `saved_cv/{timestamp}/checkoints/model_best.pth`"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "!python3 run.py UrbanSound8K/audio/fold10/100795-3-0-0.wav -r saved_cv/0818_213813/checkpoints/checkpoint-current.pth"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dog_bark 0.9858338236808777\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9H0Naj2rzq4K",
    "outputId": "a63019bc-67d5-4fd9-d8df-7d8212f7acad"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "crnn-audio-classification - UrbanSound8k.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}